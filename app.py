import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode

# ----------------------------------
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ----------------------------------
st.set_page_config(
    page_title="ë¦¬ì½”ë§¨ì¦ˆ ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ----------------------------------
# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (ìºì‹± í™œìš©)
# ----------------------------------
@st.cache_data
def load_data(filepath):
    """CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()
    df['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'] = pd.to_datetime(df['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'], errors='coerce')
    df.dropna(subset=['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'], inplace=True)
    df['ë¦¬ë·°ë‚´ìš©'] = df['ë¦¬ë·°ë‚´ìš©'].astype(str).str.strip().str.replace(r'\s+', ' ', regex=True)
    return df

# ----------------------------------
# ë¶„ì„ í•¨ìˆ˜
# ----------------------------------
okt = Okt()

# --- ë¶ˆìš©ì–´ ëª©ë¡ ì •ì˜ ---
stopwords = [
    'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ê·¸ë ‡ë‹¤', 'ì•Šë‹¤', 'ì—†ë‹¤', 'ê°™ë‹¤', 'ë³´ì´ë‹¤', 'ë“¤ë‹¤', 'ë‚˜ë‹¤', 'ì˜¤ë‹¤', 'ê°€ë‹¤', 'ì˜¨ê±´',
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ì¢€', 'ì˜', 'ë”', 'ë§ì´', 'ì¡°ê¸ˆ', 'ì •ë§', 'ì§„ì§œ', 'ë„ˆë¬´', 'ë§Œì¡±í•˜ë‹¤', 'í¸ì´',
    'ë˜', 'ë‹¤ì‹œ', 'ìƒê°', 'ëŠë‚Œ', 'ì‚¬ìš©', 'ì£¼ë¬¸', 'êµ¬ë§¤', 'ì œí’ˆ', 'ìƒí’ˆ', 'ë„¤ì´ë²„', 'ë¦¬ë·°', 'ì‚¬ì§„', 'í™•ì¸', 'ì¤‘ì´', 'ì´ë°”',
    'í•˜ë‚˜', 'ì €í¬', 'ì´ë²ˆ', 'ê·¸ëƒ¥', 'í•œë²ˆ', 'ê°™ì•„ìš”', 'ì…ë‹ˆë‹¤', 'ìˆì–´ìš”', 'í•´ìš”', 'ë˜ìš”', 'ë„¤ìš”', 'í•˜ë‹ˆ', 'ì°¨ê³ ', 'ì£¼ì‹ ',
    'í•˜ê³ ', 'í•´ì„œ', 'í•˜ë©´', 'ìœ¼ë¡œ', 'ìœ¼ë¡œë„', 'ì—ê²Œ', 'ì§€ë§Œ', 'ëŠ”ë°', 'ìŠµë‹ˆë‹¤', 'í•˜ê²Œ', 'ìœ¼ë‹ˆ', 'ë¬¸í•´', 'ì•½ê°„', 'ê¸°ë„',
    'ã…ã…', 'ã…‹ã…‹', 'ã… ã… ', '^^', ':)','~','!','.', 'í˜ì´', 'ë“±ë¡', 'ë“±ë¡ëœ', 'ì•„ë‹ˆë‹¤', 'ë¶€ë¶„', 'ì´ë‹¤', 'í•˜ë£¨', 'ë¬¼ê±´', 'ë“œë„¤'
]

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜: í˜•íƒœì†Œ ë¶„ì„ ë° ë¶ˆìš©ì–´ ì²˜ë¦¬"""
    if not isinstance(text, str):
        return ""
    morphs = okt.pos(text, stem=True, norm=True)
    words = [word for word, pos in morphs if pos in ['Noun', 'Adjective']]
    meaningful_words = [w for w in words if len(w) > 1 and w not in stopwords]
    return ' '.join(meaningful_words)

# @st.cache_data # ìºì‹± ì œê±°
def analyze_all_keywords_tfidf(_df):
    """ë°ì´í„°í”„ë ˆì„ ì „ì²´ì— ëŒ€í•´ TF-IDFë¥¼ ê³„ì‚°í•˜ê³  ë‹¨ì–´ë³„ ê¸ì •/ë¶€ì •ì„± ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    pos_reviews_df = _df[_df['ë¦¬ë·°í‰ì '].isin([4, 5])]
    neg_reviews_df = _df[_df['ë¦¬ë·°í‰ì '].isin([1, 2])]

    if pos_reviews_df.empty or neg_reviews_df.empty:
        return pd.DataFrame()

    pos_corpus = pos_reviews_df['ë¦¬ë·°ë‚´ìš©'].apply(preprocess_text)
    neg_corpus = neg_reviews_df['ë¦¬ë·°ë‚´ìš©'].apply(preprocess_text)
    
    vectorizer = TfidfVectorizer(max_features=1000)
    all_corpus = pd.concat([pos_corpus, neg_corpus])
    if all_corpus.empty or all_corpus.str.strip().eq('').all():
        return pd.DataFrame()
        
    vectorizer.fit(all_corpus)
    
    pos_tfidf_matrix = vectorizer.transform(pos_corpus)
    neg_tfidf_matrix = vectorizer.transform(neg_corpus)
    
    words = vectorizer.get_feature_names_out()
    pos_scores = np.array(pos_tfidf_matrix.mean(axis=0)).flatten()
    neg_scores = np.array(neg_tfidf_matrix.mean(axis=0)).flatten()

    tfidf_df = pd.DataFrame({'ë‹¨ì–´': words, 'ê¸ì •ì ìˆ˜': pos_scores, 'ë¶€ì •ì ìˆ˜': neg_scores})
    tfidf_df['ê¸ì •ì„±'] = tfidf_df['ê¸ì •ì ìˆ˜'] - tfidf_df['ë¶€ì •ì ìˆ˜']
    
    return tfidf_df

def get_product_negativity_score(review_series, keyword_scores):
    """ìƒí’ˆ ë¦¬ë·°ë“¤ì˜ ë¶€ì •ì„± ì ìˆ˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    total_score = 0
    word_count = 0
    neg_keyword_df = keyword_scores[keyword_scores['ê¸ì •ì„±'] < 0]
    
    for review in review_series:
        processed_review = preprocess_text(review).split()
        for word in processed_review:
            if word in neg_keyword_df['ë‹¨ì–´'].values:
                score = neg_keyword_df[neg_keyword_df['ë‹¨ì–´'] == word]['ê¸ì •ì„±'].iloc[0] * -1
                total_score += score
                word_count += 1
    
    return total_score / word_count if word_count > 0 else 0

def highlight_keywords(text, pos_keywords, neg_keywords):
    """ë¦¬ë·° í…ìŠ¤íŠ¸ ë‚´ í‚¤ì›Œë“œë¥¼ HTMLë¡œ í•˜ì´ë¼ì´íŒ…í•©ë‹ˆë‹¤."""
    if not isinstance(text, str):
        return ""
    highlighted_text = text
    for word in sorted(pos_keywords, key=len, reverse=True):
        highlighted_text = re.sub(f'({re.escape(word)})', r'<span style="color:blue; font-weight:bold;">\1</span>', highlighted_text)
    for word in sorted(neg_keywords, key=len, reverse=True):
         highlighted_text = re.sub(f'({re.escape(word)})', r'<span style="color:red; font-weight:bold;">\1</span>', highlighted_text)
    return highlighted_text

# ----------------------------------
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ UI
# ----------------------------------
df_reviews = load_data('240611-250611_Quick_Review_Filter.csv')

if not df_reviews.empty:
    st.title("ë¦¬ì½”ë§¨ì¦ˆ ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ (TF-IDF ê¸°ë°˜)")
    st.markdown("---")

    # --- ì‚¬ì´ë“œë°” ---
    st.sidebar.header("ğŸ—“ï¸ ê¸°ê°„ í•„í„°")
    min_date = df_reviews['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].min().date()
    max_date = df_reviews['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].max().date()
    start_date, end_date = st.sidebar.date_input("ì¡°íšŒí•  ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”.", (min_date, max_date), min_value=min_date, max_value=max_date, format="YYYY-MM-DD")

    filtered_df = df_reviews[(df_reviews['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].dt.date >= start_date) & (df_reviews['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].dt.date <= end_date)]

    if filtered_df.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        keyword_scores_df = analyze_all_keywords_tfidf(filtered_df)

        st.header("ì£¼ìš” ì§€í‘œ ë° íŠ¸ë Œë“œ")
        avg_rating = filtered_df['ë¦¬ë·°í‰ì '].mean()
        total_avg_rating = df_reviews['ë¦¬ë·°í‰ì '].mean()
        st.metric(label="ê¸°ê°„ ë‚´ ì „ì²´ í‰ê·  í‰ì ", value=f"{avg_rating:.2f} ì ", delta=f"{avg_rating - total_avg_rating:.2f} (ì „ì²´ í‰ê·  ëŒ€ë¹„)")

        time_diff = end_date - start_date
        
        if time_diff.days > 60:
            period_name = "ì›”ë³„"
            agg_df = filtered_df.set_index('ë¦¬ë·°ì‘ì„±ì¼ì‹œ').groupby(pd.Grouper(freq='M')).agg(ë¦¬ë·°ê°œìˆ˜=('ë¦¬ë·°ë²ˆí˜¸', 'count'), í‰ê· í‰ì =('ë¦¬ë·°í‰ì ', 'mean')).reset_index()
            agg_df = agg_df[agg_df['ë¦¬ë·°ê°œìˆ˜'] > 0]
            agg_df['ê¸°ê°„'] = agg_df['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].dt.strftime('%Y-%m')
        else:
            period_name = "ì¼ë³„"
            agg_df = filtered_df.set_index('ë¦¬ë·°ì‘ì„±ì¼ì‹œ').groupby(pd.Grouper(freq='D')).agg(ë¦¬ë·°ê°œìˆ˜=('ë¦¬ë·°ë²ˆí˜¸', 'count'), í‰ê· í‰ì =('ë¦¬ë·°í‰ì ', 'mean')).reset_index()
            agg_df = agg_df[agg_df['ë¦¬ë·°ê°œìˆ˜'] > 0]
            agg_df['ê¸°ê°„'] = agg_df['ë¦¬ë·°ì‘ì„±ì¼ì‹œ'].dt.strftime('%m-%d')

        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        fig.add_trace(go.Bar(x=agg_df['ê¸°ê°„'], y=agg_df['ë¦¬ë·°ê°œìˆ˜'], name='ë¦¬ë·° ê°œìˆ˜', marker_color='skyblue', text=agg_df['ë¦¬ë·°ê°œìˆ˜'], textposition='outside', textfont=dict(size=10)), secondary_y=False)
        fig.add_trace(go.Scatter(x=agg_df['ê¸°ê°„'], y=agg_df['í‰ê· í‰ì '], name='í‰ê·  í‰ì ', mode='lines+markers', marker_color='darkorange'), secondary_y=True)

        fig.update_layout(title_text=f'<b>{period_name} ë¦¬ë·° ê°œìˆ˜ ë° í‰ê·  í‰ì  íŠ¸ë Œë“œ</b>', xaxis_title=period_name, legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1), plot_bgcolor='rgba(0,0,0,0)', yaxis=dict(gridcolor='rgba(0,0,0,0)'), yaxis2=dict(gridcolor='rgba(0,0,0,0)'), xaxis=dict(showgrid=False, type='category', tickangle=-45), uniformtext_minsize=8, uniformtext_mode='hide')
        fig.update_yaxes(title_text="<b>ë¦¬ë·° ê°œìˆ˜</b> (ê±´)", secondary_y=False, showgrid=False, zeroline=False)
        fig.update_yaxes(title_text="<b>í‰ê·  í‰ì </b> (ì )", secondary_y=True, range=[1, 5], showgrid=False, zeroline=False)

        st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")

        st.header("ê¸ì • & ë¶€ì • í‚¤ì›Œë“œ ë¶„ì„")
        with st.expander("TF-IDF ê¸°ë°˜ ê°ì„±ë¶„ì„ ì„¤ëª… ë³´ê¸°"):
            st.markdown("""ê¸°ì¡´ì˜ ê³ ì •ëœ ê°ì„± ì‚¬ì „ì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , **ì‹¤ì œ ë¦¬ë·° ë°ì´í„° ìì²´ë¥¼ í•™ìŠµí•˜ì—¬** ê¸ì •/ë¶€ì • í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ë°©ì‹ì…ë‹ˆë‹¤.

        1. ë°ì´í„° ê·¸ë£¹í™”: ë¨¼ì € ë¦¬ë·°ë¥¼ ê¸ì • ê·¸ë£¹(4-5ì )ê³¼ ë¶€ì • ê·¸ë£¹(1-2ì )ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
            
        2. TF-IDF ì ìˆ˜ ê³„ì‚°: ê° ê·¸ë£¹ ë‚´ì—ì„œ íŠ¹ì • ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ê³ (TF), ë‹¤ë¥¸ ê·¸ë£¹ì—ì„œëŠ” ì–¼ë§ˆë‚˜ ë“œë¬¼ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€(IDF)ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¨ì–´ì˜ ì¤‘ìš”ë„(TF-IDF ì ìˆ˜)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            
        3. 'ê¸ì •ì„±' ì ìˆ˜í™”: í•œ ë‹¨ì–´ì˜ ê¸ì • ê·¸ë£¹ TF-IDF í‰ê·  ì ìˆ˜ì—ì„œ ë¶€ì • ê·¸ë£¹ TF-IDF í‰ê·  ì ìˆ˜ë¥¼ ëº€ ê°’ì„ ê¸ì •ì„± ì ìˆ˜ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
            - ì´ ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ë‹¨ì–´ëŠ” ê¸ì •ì ì¸ ë§¥ë½ì—ì„œ ë” ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©ë˜ì—ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. (ì˜ˆ: `ì¬êµ¬ë§¤`, `ê³ ê¸‰`)
            - ì´ ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡(ìŒìˆ˜ì¼ìˆ˜ë¡) ë¶€ì •ì ì¸ ë§¥ë½ì—ì„œ ë” ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©ë˜ì—ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. (ì˜ˆ: `ë¶„ì‹¤`, `ë³€ìƒ‰`, `ìì„`)
            
        ì´ ë°©ì‹ì„ í†µí•´, 'ê°€ê²© ëŒ€ë¹„'(ë¶€ì •)ë‚˜ 'ì„ ë¬¼ìš©'(ê¸ì •)ì²˜ëŸ¼ ìš°ë¦¬ ì‡¼í•‘ëª°ì˜ ê³ ìœ í•œ ë§¥ë½ì´ ë‹´ê¸´ í•µì‹¬ í‚¤ì›Œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.""")

        if not keyword_scores_df.empty:
            pos_keywords_df = keyword_scores_df[keyword_scores_df['ê¸ì •ì ìˆ˜'] > 0.01].sort_values(by='ê¸ì •ì„±', ascending=False).head(10)
            neg_keywords_df = keyword_scores_df[keyword_scores_df['ë¶€ì •ì ìˆ˜'] > 0.01].sort_values(by='ê¸ì •ì„±', ascending=True).head(10)
            
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ‘ ê¸ì • í‚¤ì›Œë“œ TOP 10")
                st.dataframe(pos_keywords_df[['ë‹¨ì–´', 'ê¸ì •ì„±']].rename(columns={'ë‹¨ì–´': 'í‚¤ì›Œë“œ', 'ê¸ì •ì„±': 'ê¸ì •ì„± ì ìˆ˜'}), use_container_width=True, hide_index=True)
            with col2:
                st.subheader("ğŸ‘ ë¶€ì • í‚¤ì›Œë“œ TOP 10")
                st.dataframe(neg_keywords_df[['ë‹¨ì–´', 'ê¸ì •ì„±']].rename(columns={'ë‹¨ì–´': 'í‚¤ì›Œë“œ', 'ê¸ì •ì„±': 'ê¸ì •ì„± ì ìˆ˜'}), use_container_width=True, hide_index=True)
        else:
            st.info("í‚¤ì›Œë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ê¸ì •/ë¶€ì • ë¦¬ë·°ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤).")

        st.markdown("---")

        st.header("ê°œì„  í•„ìš” ìƒí’ˆ ë¶„ì„")
        st.info("ê°œì„ ì´ í•„ìš”í•œ ìƒí’ˆ ëª©ë¡ì…ë‹ˆë‹¤. **í‘œì˜ í–‰ì„ í´ë¦­**í•˜ë©´ ì•„ë˜ì—ì„œ ìƒì„¸ ë¦¬ë·°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        with st.expander("ê°œì„  í•„ìš” ì ìˆ˜ ì‚°ì • ë°©ì‹ ì„¤ëª… ë³´ê¸°"):
            st.markdown("""**ê°œì„  í•„ìš” ì ìˆ˜**ëŠ” ìƒí’ˆë³„ ê°œì„  ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ê¸° ìœ„í•œ ì§€í‘œì…ë‹ˆë‹¤. ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ë§ì€ ê³ ê°ì´ ë¶ˆí¸ì„ ê²ªê³  ìˆì–´ ìš°ì„ ì ì¸ ê°œì„ ì´ í•„ìš”í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

     1.  TF-IDF ë¶€ì •ì„± ì˜í–¥ (ê°€ì¤‘ì¹˜ 20%): í•´ë‹¹ ìƒí’ˆì˜ ë¦¬ë·°ì— ë“±ì¥í•œ ë¶€ì • í‚¤ì›Œë“œë“¤ì˜ TF-IDF ê¸°ë°˜ ë¶€ì •ì„± ì ìˆ˜ë¥¼ í‰ê· ë‚´ì–´ ê³„ì‚°í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ë¶€ì • ë‹¨ì–´ì˜ ë¹ˆë„ê°€ ì•„ë‹Œ, 'ì–¼ë§ˆë‚˜ ê°•í•œ' ë¶€ì • í‘œí˜„ì´ ì“°ì˜€ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
            
     2.  ë¦¬ë·° ìˆ˜ë¥¼ ë°˜ì˜í•œ ë‚®ì€ í‰ì  ì˜í–¥ (ê°€ì¤‘ì¹˜ 70%): ì¸ê¸° ìƒí’ˆ(ë¦¬ë·° ìˆ˜ê°€ ë§ì€ ìƒí’ˆ)ì˜ ë‚®ì€ í‰ì ì— ë” í° í˜ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. ë§ì€ ê³ ê°ì´ ê²½í—˜í•˜ëŠ” ëŒ€í‘œì ì¸ ë¶ˆë§Œì¼ìˆ˜ë¡ ê°œì„ ì´ ì‹œê¸‰í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
            
     3.  í‰ì  ë³€ë™ì„± ì˜í–¥ (ê°€ì¤‘ì¹˜ 10%): í‰ì ì˜ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ì˜ ì¼ê´€ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤. í˜¸ë¶ˆí˜¸ê°€ ì‹¬í•˜ê²Œ ê°ˆë¦¬ëŠ” ìƒí’ˆì„ ì‹ë³„í•©ë‹ˆë‹¤.""")
            
        with st.spinner("ê°œì„  í•„ìš” ìƒí’ˆ ë¶„ì„ ì¤‘..."):
            product_stats = filtered_df.groupby(['ìƒí’ˆëª…', 'ìƒí’ˆì½”ë“œ']).agg(ë¦¬ë·°ìˆ˜=('ë¦¬ë·°ë²ˆí˜¸', 'count'), í‰ê· í‰ì =('ë¦¬ë·°í‰ì ', 'mean'), í‰ì í‘œì¤€í¸ì°¨=('ë¦¬ë·°í‰ì ', 'std')).reset_index()
            product_stats['í‰ì í‘œì¤€í¸ì°¨'].fillna(0, inplace=True)

            if not keyword_scores_df.empty:
                product_stats['ë¶€ì •ì„±ì ìˆ˜'] = product_stats.apply(lambda row: get_product_negativity_score(filtered_df[filtered_df['ìƒí’ˆì½”ë“œ'] == row['ìƒí’ˆì½”ë“œ']]['ë¦¬ë·°ë‚´ìš©'], keyword_scores_df), axis=1)
                max_log_reviews = np.log1p(product_stats['ë¦¬ë·°ìˆ˜'].max())
                product_stats['ë¦¬ë·°ìˆ˜ê°€ì¤‘ì¹˜'] = np.log1p(product_stats['ë¦¬ë·°ìˆ˜']) / max_log_reviews if max_log_reviews > 0 else 0
                max_neg_score = product_stats['ë¶€ì •ì„±ì ìˆ˜'].max()
                negativity_norm = product_stats['ë¶€ì •ì„±ì ìˆ˜'] / max_neg_score if max_neg_score > 0 else 0
                low_rating_norm = ((5 - product_stats['í‰ê· í‰ì ']) / 4) * product_stats['ë¦¬ë·°ìˆ˜ê°€ì¤‘ì¹˜']
                std_dev_norm = product_stats['í‰ì í‘œì¤€í¸ì°¨'] / 2
                w_neg, w_rating, w_std = 0.2, 0.7, 0.1
                product_stats['ê°œì„ í•„ìš”ì ìˆ˜'] = (negativity_norm * w_neg + low_rating_norm * w_rating + std_dev_norm * w_std) * 100
            else:
                product_stats['ë¶€ì •ì„±ì ìˆ˜'] = 0
                product_stats['ê°œì„ í•„ìš”ì ìˆ˜'] = 0

            improvement_df = product_stats.sort_values(by='ê°œì„ í•„ìš”ì ìˆ˜', ascending=False)
            display_cols = ['ìƒí’ˆëª…', 'ë¦¬ë·°ìˆ˜', 'í‰ê· í‰ì ', 'ë¶€ì •ì„±ì ìˆ˜', 'ê°œì„ í•„ìš”ì ìˆ˜']
            improvement_df_display = improvement_df[display_cols].reset_index(drop=True)
            improvement_df_display['í‰ê· í‰ì '] = improvement_df_display['í‰ê· í‰ì '].round(1)
            improvement_df_display['ë¶€ì •ì„±ì ìˆ˜'] = improvement_df_display['ë¶€ì •ì„±ì ìˆ˜'].round(3)
            improvement_df_display['ê°œì„ í•„ìš”ì ìˆ˜'] = improvement_df_display['ê°œì„ í•„ìš”ì ìˆ˜'].round(1)

            gb = GridOptionsBuilder.from_dataframe(improvement_df_display)
            gb.configure_selection('single', use_checkbox=False)
            
            # domLayout='autoHeight' ì˜µì…˜ì„ ì œê±°í•©ë‹ˆë‹¤.
            grid_options = gb.build()

            grid_response = AgGrid(
                improvement_df_display,
                gridOptions=grid_options,
                height=400,  # ê·¸ë¦¬ë“œì˜ ë†’ì´ë¥¼ 400pxë¡œ ê³ ì •í•˜ì—¬ ìŠ¤í¬ë¡¤ë°” ìƒì„±
                update_mode=GridUpdateMode.MODEL_CHANGED,
                allow_unsafe_jscode=True,
                theme='streamlit',
                key='product_grid'
            )
            
            selected_rows = grid_response['selected_rows']
            
            if selected_rows is not None and not selected_rows.empty:
                selected_product_name = selected_rows.iloc[0]['ìƒí’ˆëª…']
            
                st.markdown("---")
                st.header(f"ğŸ” '{selected_product_name}' ìƒì„¸ ë¦¬ë·°")
                
                detail_df = filtered_df[filtered_df['ìƒí’ˆëª…'] == selected_product_name]
                
                if not keyword_scores_df.empty:
                    pos_k_list = keyword_scores_df[keyword_scores_df['ê¸ì •ì„±'] > 0]['ë‹¨ì–´'].tolist()
                    neg_k_list = keyword_scores_df[keyword_scores_df['ê¸ì •ì„±'] < 0]['ë‹¨ì–´'].tolist()
                else:
                    pos_k_list, neg_k_list = [], []
                
                for _, row in detail_df.iterrows():
                    rating_stars = "â­" * int(row['ë¦¬ë·°í‰ì ']) + "â˜†" * (5 - int(row['ë¦¬ë·°í‰ì ']))
                    st.markdown(f"**í‰ì :** {rating_stars} (`{row['ë¦¬ë·°í‰ì ']}`ì )")
                    
                    highlighted_review = highlight_keywords(row['ë¦¬ë·°ë‚´ìš©'], pos_k_list, neg_k_list)
                    st.markdown(f"> {highlighted_review}", unsafe_allow_html=True)
                    st.markdown("---")